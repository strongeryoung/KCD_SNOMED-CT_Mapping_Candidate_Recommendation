{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kigkkWOxfuOl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 0. ì „ì²˜ë¦¬ ëª¨ë“ˆ ê°œìš” (ver5 â€“ rule-based + ì˜ë£Œ ì˜ë¯¸ ë³´í˜¸)\n",
        "# ---------------------------------------------------------\n",
        "# ì´ ëª¨ë“ˆì€ KCD/SNOMED ìš©ì–´ë¥¼ ë™ì¼í•œ ê·œì¹™(v1.5)ì— ë”°ë¼ ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ê³µí†µ í•¨ìˆ˜ ì§‘í•©ì…ë‹ˆë‹¤.\n",
        "# ëª©í‘œ:\n",
        "#   - KCD/SNOMED ëª¨ë‘ì— ëŒ€í•´ ì¼ê´€ëœ ì •ê·œí™” ê·œì¹™ ìœ ì§€\n",
        "#   - ë§¤í•‘ì— ì¤‘ìš”í•œ ì˜ë£Œ ì˜ë¯¸(benign/malignant, acute/chronic, due to, etc.)ëŠ” ìµœëŒ€í•œ ë³´ì¡´\n",
        "#   - ë¶ˆí•„ìš”í•œ ë©”íƒ€ í‘œí˜„ë§Œ ì œê±° (NOS, otherwise specified, with/without cavitation ë“±)\n",
        "#   - ì´í›„ ëª¨ë¸ë§/ì¬ë­í‚¹ ë‹¨ê³„ì—ì„œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ modifier ì •ë³´ë„ í•¨ê»˜ ì œê³µ\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. ì„¤ì •: ë¶ˆìš©ì–´ / ê¸°ëŠ¥ì–´ / ì˜ˆì™¸ ë‹¨ì–´ / modifier ì‚¬ì „\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1-1. ê´„í˜¸ íƒœê·¸ ì¤‘ \"ì™„ì „ ë©”íƒ€\"ë¡œ ê°„ì£¼í•´ì„œ ë²„ë¦´ ê²ƒë“¤ (SNOMED FSN íƒœê·¸ ë“±)\n",
        "GENERIC_PAREN_TAGS = {\n",
        "    \"disorder\",\n",
        "    \"finding\",\n",
        "    \"procedure\",\n",
        "    \"body structure\",\n",
        "    \"morphologic abnormality\",\n",
        "    \"situation\",\n",
        "    \"event\",\n",
        "    \"observable entity\",\n",
        "    \"organism\",\n",
        "    \"substance\",\n",
        "    \"pharmaceutical / biologic product\",\n",
        "    \"qualifier value\",\n",
        "    \"physical object\",\n",
        "    \"environments and geographical locations\",\n",
        "}\n",
        "\n",
        "# 1-2. ë„ë©”ì¸ ê³µí†µ ë¶ˆìš©ì–´ (ì˜ë¯¸ì  impactê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ë©”íƒ€ í‘œí˜„)\n",
        "# ğŸ‘‰ ver5ì—ì„œëŠ” ì˜ë¯¸ë¥¼ ë§ì´ í›¼ì†í•˜ëŠ” ë‹¨ì–´(\"other\", \"due to\", \"associated with\" ë“±)ëŠ” STOPWORDSì—ì„œ ì œê±°\n",
        "STOPWORDS = [\n",
        "    # NOS / specified / unspecified ê³„ì—´: ë„ˆë¬´ ìì£¼ ë‚˜ì˜¤ê³  ì˜ë¯¸ê°€ ì•½í•œ ë©”íƒ€ ì •ë³´\n",
        "    \"not otherwise specified\",\n",
        "    \"otherwise specified\",\n",
        "    \"other and unspecified\",\n",
        "    \"other and unspecified parts of\",\n",
        "    \"other and ill-defined parts of\",\n",
        "    \"ill-defined\",\n",
        "    \"unspecified part of\",\n",
        "    \"other parts of\",\n",
        "    \"other unspecified\",\n",
        "    \"other forms of\",\n",
        "    \"unspecified side\",\n",
        "    \"nos\",\n",
        "\n",
        "    # ìœ„ì¹˜/ë¶€ìœ„ í‘œí˜„ ì¤‘ ë©”íƒ€ì ì¸ ê²ƒë“¤\n",
        "    \"part of\",\n",
        "    \"parts of\",\n",
        "    \"site of\",\n",
        "    \"portion of\",\n",
        "    \"sites\",\n",
        "    \"other sites\",\n",
        "\n",
        "    # í™•ì¸/ê²€ì‚¬ ë°©ì‹ ê´€ë ¨ ë©”íƒ€ í‘œí˜„\n",
        "    \"confirmed by\",\n",
        "    \"confirmed only\",\n",
        "    \"confirmed histologically\",\n",
        "    \"confirmed bacteriologically\",\n",
        "\n",
        "    # ì§„í–‰ ì–‘ìƒ ë©”íƒ€ í‘œí˜„\n",
        "    \"with cavitation\",\n",
        "    \"without cavitation\",\n",
        "    \"with or without\",\n",
        "]\n",
        "\n",
        "# âš ï¸ ì£¼ì˜: ì•„ë˜ ë‹¨ì–´/êµ¬ëŠ” STOPWORDSì—ì„œ *ì œê±°*í–ˆìŠµë‹ˆë‹¤ (ì˜ë¯¸ ë³´ì¡´ì„ ìœ„í•´).\n",
        "#   - \"other\" (ë‹¨ë…)\n",
        "#   - \"specified\"\n",
        "#   - \"unspecified\"\n",
        "#   - \"due to\"\n",
        "#   - \"associated with\"\n",
        "#   - \"resulting in\"\n",
        "#   â†’ ì´ë“¤ì€ ë‚˜ì¤‘ì— rule-based rerankì—ì„œ modifierë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ê·¸ëŒ€ë¡œ ë‘ëŠ” ê²ƒì´ ì¢‹ìŒ.\n",
        "\n",
        "# 1-3. ê¸°ëŠ¥ì–´(function words) â€“ query relaxation ë‹¨ê³„ì—ì„œ ì„ íƒì  ì œê±°ìš©\n",
        "FUNCTION_WORDS = [\"of\", \"the\", \"for\", \"in\", \"a\", \"an\"]\n",
        "\n",
        "# 1-4. ë³µìˆ˜í˜• ì˜ˆì™¸ ë‹¨ì–´ ëª©ë¡ (s ì œê±°í•˜ë©´ ì•ˆ ë˜ëŠ” ë‹¨ì–´ë“¤)\n",
        "EXCEPTION_WORDS = [\n",
        "    # ê°ì—¼ì„± ì§ˆí™˜ë¥˜\n",
        "    \"tuberculosis\",\n",
        "    \"measles\",\n",
        "    \"mumps\",\n",
        "    \"rabies\",\n",
        "    \"pertussis\",\n",
        "    \"rubella\",\n",
        "    \"salmonellosis\",\n",
        "    \"shigellosis\",\n",
        "    \"amoebiasis\",\n",
        "    \"giardiasis\",\n",
        "    \"cryptosporidiosis\",\n",
        "    \"isosporiasis\",\n",
        "    \"balantidiasis\",\n",
        "    \"trichomoniasis\",\n",
        "    \"coccidiosis\",\n",
        "\n",
        "    # ì—¼ì¦/ì§ˆí™˜ ê³„ì—´\n",
        "    \"enteritis\",\n",
        "    \"colitis\",\n",
        "    \"gastritis\",\n",
        "    \"pneumonitis\",\n",
        "    \"hepatitis\",\n",
        "    \"dermatitis\",\n",
        "    \"encephalitis\",\n",
        "    \"lymphadenitis\",\n",
        "    \"appendicitis\",\n",
        "\n",
        "    # ê¸°íƒ€ í•´ë¶€/ì§ˆí™˜ ìš©ì–´\n",
        "    \"abscess\",\n",
        "    \"sinus\",\n",
        "    \"sepsis\",\n",
        "    \"anus\",\n",
        "    \"bronchus\",\n",
        "    \"thymus\",\n",
        "    \"lens\",\n",
        "    \"iris\",\n",
        "    \"mass\",\n",
        "    \"gas\",\n",
        "    \"stress\",\n",
        "\n",
        "    # ì¶”ê°€ ë³´í˜¸ ë‹¨ì–´ (ver5 ë³´ê°•)\n",
        "    \"virus\",\n",
        "    \"fungus\",\n",
        "    \"fungi\",\n",
        "    \"coccus\",\n",
        "    \"cocci\",\n",
        "    \"bacterium\",\n",
        "    \"bacteria\",\n",
        "]\n",
        "\n",
        "# 1-5. íŒ¨í„´ ê¸°ë°˜ ì˜ˆì™¸ suffix\n",
        "EXCEPTION_SUFFIXES = [\"itis\", \"osis\", \"iasis\", \"esis\", \"us\"]\n",
        "\n",
        "# 1-6. ì˜í•™ì  modifier ì‚¬ì „ (ë‚˜ì¤‘ì— rule-based rerankì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¶”ì¶œìš©)\n",
        "MODIFIER_PATTERNS = {\n",
        "    \"behavior\": [\n",
        "        \"benign\",\n",
        "        \"malignant\",\n",
        "        \"in situ\",\n",
        "        \"unspecified\",\n",
        "    ],\n",
        "    \"temporal\": [\n",
        "        \"acute\",\n",
        "        \"subacute\",\n",
        "        \"chronic\",\n",
        "        \"recurrent\",\n",
        "        \"persistent\",\n",
        "    ],\n",
        "    \"relation\": [\n",
        "        \"due to\",\n",
        "        \"associated with\",\n",
        "        \"resulting in\",\n",
        "        \"secondary to\",\n",
        "        \"following\",\n",
        "    ],\n",
        "    \"extent\": [\n",
        "        \"local\",\n",
        "        \"localized\",\n",
        "        \"generalized\",\n",
        "        \"systemic\",\n",
        "        \"diffuse\",\n",
        "        \"focal\",\n",
        "    ],\n",
        "    \"laterality\": [\n",
        "        \"left\",\n",
        "        \"right\",\n",
        "        \"bilateral\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ê·œí™” (v1.5)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def _strip_generic_parentheses(text: str) -> str:\n",
        "    \"\"\"\n",
        "    ê´„í˜¸ ì²˜ë¦¬ ê·œì¹™ (ver5):\n",
        "      - ê´„í˜¸ ì•ˆ ë‚´ìš©ì´ GENERIC_PAREN_TAGSì— í•´ë‹¹í•˜ë©´ í†µì§¸ë¡œ ì œê±°\n",
        "      - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê´„í˜¸ë§Œ ì œê±°í•˜ê³  ë‚´ìš©ì€ ì‚´ë ¤ì„œ ë¬¸ìì—´ì— í¬í•¨\n",
        "        ì˜ˆ: \"pyelonephritis (acute)\" â†’ \"pyelonephritis acute\"\n",
        "    \"\"\"\n",
        "    def repl(m: re.Match) -> str:\n",
        "        inner = m.group(1).strip()\n",
        "        inner_lower = inner.lower()\n",
        "        if inner_lower in GENERIC_PAREN_TAGS:\n",
        "            return \" \"  # ì™„ì „ ë©”íƒ€ íƒœê·¸: ë‚´ìš©ë„ ì œê±°\n",
        "        else:\n",
        "            return f\" {inner} \"  # ê´„í˜¸ë§Œ ì œê±°í•˜ê³  ë‚´ìš©ì€ ìœ ì§€\n",
        "\n",
        "    return re.sub(r\"\\(([^)]*)\\)\", repl, text)\n",
        "\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    v5.1 ê·œì¹™:\n",
        "      - ì†Œë¬¸ì ë³€í™˜ ì œê±° (ì˜ë£Œ ë„ë©”ì¸ ì˜ë¯¸ ë³´í˜¸)\n",
        "      - ê´„í˜¸ ë‚´ìš© ì²˜ë¦¬\n",
        "      - ë¶ˆí•„ìš”í•œ ê¸°í˜¸/ê³µë°± ì •ë¦¬\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 0) ì–‘ìª½ ê³µë°± ì œê±°\n",
        "    text = text.strip()\n",
        "\n",
        "    # 1) ê´„í˜¸: FSN ë©”íƒ€ íƒœê·¸ë§Œ ì œê±°, ì˜ë¯¸ ìˆëŠ” ë‚´ìš© ìœ ì§€\n",
        "    text = _strip_generic_parentheses(text)\n",
        "\n",
        "    # 2) ì¤„ë°”ê¿ˆ/íƒ­ â†’ ê³µë°±\n",
        "    text = re.sub(r\"[\\n\\t]\", \" \", text)\n",
        "\n",
        "    # 3) íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬\n",
        "    text = text.replace(\",\", \" \").replace(\";\", \" \").replace(\":\", \" \")\n",
        "    text = text.replace(\"'\", \" \")\n",
        "\n",
        "    # 4) í•˜ì´í”ˆ: a-b â†’ a b (ëŒ€ì†Œë¬¸ì ëª¨ë‘ ê³ ë ¤)\n",
        "    text = re.sub(r\"([A-Za-z])\\-([A-Za-z])\", r\"\\1 \\2\", text)\n",
        "\n",
        "    # 5) ì¤‘ë³µ ê³µë°± ì •ë¦¬\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. ë„ë©”ì¸ ë¶ˆìš©ì–´ ì œê±° (ver5 â€“ ì™„í™” ë²„ì „)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    \"\"\"\n",
        "    ver5 ë¶ˆìš©ì–´ ì œê±°:\n",
        "      - STOPWORDSì— ì •ì˜ëœ phrase/ë‹¨ì–´ë¥¼ ì œê±°\n",
        "      - ê¸´ phraseë¶€í„° ì œê±°í•˜ê¸° ìœ„í•´ ê¸¸ì´ ìˆœìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
        "      - 'due to', 'associated with', 'resulting in', 'other' ë“±ì€ *ì œê±°í•˜ì§€ ì•ŠìŒ*\n",
        "    \"\"\"\n",
        "    out = text\n",
        "    for sw in sorted(STOPWORDS, key=len, reverse=True):\n",
        "        pattern = rf\"\\b{re.escape(sw)}\\b\"\n",
        "        out = re.sub(pattern, \" \", out)\n",
        "    out = re.sub(r\"\\s+\", \" \", out).strip()\n",
        "    return out\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. ë³µìˆ˜í˜• â†’ ë‹¨ìˆ˜í˜• ì •ê·œí™” (3ë²ˆ ê·œì¹™: ë³´ìˆ˜ì  ì ìš©)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def normalize_plural_word(word: str) -> str:\n",
        "    \"\"\"\n",
        "    - ì˜ˆì™¸ ë‹¨ì–´(EXCEPTION_WORDS)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "    - ì˜ˆì™¸ suffix(EXCEPTION_SUFFIXES)ë¡œ ëë‚˜ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€ (itis, osis, iasis, esis, us ë“±)\n",
        "    - ê·¸ ì™¸, ê¸¸ì´ > 3 ì´ë©´ì„œ së¡œ ëë‚˜ëŠ” ë‹¨ì–´ëŠ” s ì œê±°\n",
        "      (ex: lungs -> lung, kidneys -> kidney)\n",
        "    \"\"\"\n",
        "    if word in EXCEPTION_WORDS:\n",
        "        return word\n",
        "\n",
        "    for suf in EXCEPTION_SUFFIXES:\n",
        "        if word.endswith(suf):\n",
        "            return word\n",
        "\n",
        "    if word.endswith(\"s\") and len(word) > 3:\n",
        "        return word[:-1]\n",
        "\n",
        "    return word\n",
        "\n",
        "\n",
        "def normalize_plural(text: str) -> str:\n",
        "    tokens = text.split()\n",
        "    tokens = [normalize_plural_word(t) for t in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. í•´ë¶€í•™/ë³‘ë¦¬ ë¶„ë¦¬ (4ë²ˆ ê·œì¹™)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def split_pathology_and_anatomy(text: str):\n",
        "    \"\"\"\n",
        "    4-1, 4-2 ê·œì¹™:\n",
        "      - ì²« ë²ˆì§¸ ' of 'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì•: pathology, ë’¤: anatomy\n",
        "      - ì˜ˆ: 'carcinoma in situ of anus and anal canal'\n",
        "        â†’ pathology: 'carcinoma in situ'\n",
        "        â†’ anatomy: 'anus and anal canal'\n",
        "    \"\"\"\n",
        "    if \" of \" not in text:\n",
        "        return text.strip(), \"\"\n",
        "\n",
        "    parts = text.split(\" of \", 1)\n",
        "    pathology = parts[0].strip()\n",
        "    anatomy = parts[1].strip()\n",
        "    return pathology, anatomy\n",
        "\n",
        "\n",
        "def split_anatomy_list(anatomy_str: str):\n",
        "    \"\"\"\n",
        "    anatomy ì˜ì—­ì„ ','ì™€ 'and'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.\n",
        "    ì˜ˆ: 'anus and anal canal' -> ['anus', 'anal canal']\n",
        "    \"\"\"\n",
        "    if not anatomy_str:\n",
        "        return []\n",
        "\n",
        "    tmp = anatomy_str.replace(\",\", \" and \")\n",
        "    parts = [p.strip() for p in tmp.split(\" and \") if p.strip()]\n",
        "    return parts\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. Query Relaxationìš© ì¿¼ë¦¬ í›„ë³´ ìƒì„± (6ë²ˆ ê·œì¹™)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def generate_query_candidates(source_term: str):\n",
        "    \"\"\"\n",
        "    Query Relaxation ë‹¨ê³„:\n",
        "      - Step 0: normalize_text\n",
        "      - Step 1: + stopword ì œê±°\n",
        "      - Step 2: + ë³µìˆ˜í˜• â†’ ë‹¨ìˆ˜í˜•\n",
        "    (function words(of, in, for, the, a, an) ì œê±° ë‹¨ê³„ëŠ” ë³„ë„ ë¡œì§ì—ì„œ í•„ìš” ì‹œ ì¶”ê°€)\n",
        "    \"\"\"\n",
        "    step0 = normalize_text(source_term)\n",
        "    step1 = remove_stopwords(step0)\n",
        "    step2 = normalize_plural(step1)\n",
        "    return [step0, step1, step2]\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 7. ì˜í•™ì  modifier ì¶”ì¶œ (rule-based)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def extract_modifiers(text: str):\n",
        "    \"\"\"\n",
        "    ì›ë¬¸(ë˜ëŠ” normalize í›„ í…ìŠ¤íŠ¸)ì—ì„œ ì˜í•™ì  modifier(acute, chronic, benign, malignant, due to ë“±)ë¥¼\n",
        "    rule-basedë¡œ ì¶”ì¶œí•˜ì—¬ dict í˜•íƒœë¡œ ë°˜í™˜.\n",
        "\n",
        "    ë°˜í™˜ ì˜ˆ:\n",
        "      {\n",
        "        \"behavior\": [\"benign\"],\n",
        "        \"temporal\": [\"acute\"],\n",
        "        \"relation\": [\"due to\"],\n",
        "        ...\n",
        "      }\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return {}\n",
        "\n",
        "    t = text.lower()\n",
        "    found = {}\n",
        "\n",
        "    for cat, patterns in MODIFIER_PATTERNS.items():\n",
        "        hits = []\n",
        "        for p in patterns:\n",
        "            # phrase ë‹¨ìœ„ ë§¤ì¹­ (ê³µë°± í¬í•¨)\n",
        "            pattern = rf\"\\b{re.escape(p)}\\b\"\n",
        "            if re.search(pattern, t):\n",
        "                hits.append(p)\n",
        "        if hits:\n",
        "            found[cat] = sorted(set(hits))\n",
        "\n",
        "    return found\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 8. ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (KCD/SNOMED ìš©ì–´ 1ê°œ ë‹¨ìœ„)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def preprocess_kcd_term(source_term: str):\n",
        "    \"\"\"\n",
        "    KCD ì˜ë¬¸ ìš©ì–´ í•˜ë‚˜ì— ëŒ€í•´ full pipeline (ver5):\n",
        "      - normalized: ê¸°ë³¸ ì •ê·œí™”(ì†Œë¬¸ì, ê´„í˜¸ ì²˜ë¦¬, êµ¬ë‘ì /ê³µë°± ì •ë¦¬)\n",
        "      - no_stopwords: ë„ë©”ì¸ ë¶ˆìš©ì–´ ì œê±°\n",
        "      - no_plural: ë³µìˆ˜í˜• ì •ê·œí™”\n",
        "      - pathology / anatomy_list ë¶„ë¦¬ (4ë²ˆ ê·œì¹™)\n",
        "      - query_candidates: Step0~2 ì¿¼ë¦¬ ë¬¸ìì—´\n",
        "      - modifiers: behavior/temporal/relation/extent/laterality ë“±ì˜ modifier ì¶”ì¶œ ê²°ê³¼\n",
        "    \"\"\"\n",
        "    normalized = normalize_text(source_term)\n",
        "    no_sw = remove_stopwords(normalized)\n",
        "    no_plural = normalize_plural(no_sw)\n",
        "\n",
        "    pathology, anatomy = split_pathology_and_anatomy(no_plural)\n",
        "    anatomy_list = split_anatomy_list(anatomy)\n",
        "\n",
        "    modifiers = extract_modifiers(source_term)\n",
        "\n",
        "    return {\n",
        "        \"normalized\": normalized,\n",
        "        \"no_stopwords\": no_sw,\n",
        "        \"no_plural\": no_plural,\n",
        "        \"pathology\": pathology,\n",
        "        \"anatomy_list\": anatomy_list,\n",
        "        \"query_candidates\": generate_query_candidates(source_term),\n",
        "        \"modifiers\": modifiers,\n",
        "    }"
      ]
    }
  ]
}